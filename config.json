{
	"glove":{
		"Comment_":"#Specifications of the glove model to use",
        	"dir":"./data/glove",
        	"corpus":"6B",
        	"vec_size":"100",
        	"db":"write-math"
    },
	"directories":{
		"Comment_":"#Directories info.",
		"source_dir":"./data/squad/",
		"target_dir":"./",
		"dir":"./",
		"plots":"./plots/"
	},
	"pre":{
		"Comments_":"Define preprocessing. Run: if the preprocess is run. Split: Split paragraph into sentences. word_count_th=number of times a word nees to appear to be counted as known",
		"run": true,
		"n_chunks": 30,
		"finetune": false,
		"data_filter": true,
		"word_count_th": 100,
		"char_count_th": 50,
		"max_question_size": 60,
		"max_paragraph_size": 400,
		"max_word_size": 20,
		"known_if_glove": true,
		"use_glove_for_unk": true,
		"number_of_unk":1
	},
	"model":{
		"Comment_":"All variables related to the model's architecture and training",
                "name": "ID290 word, double_conv, Q=0.25X freq 1-10k, 3:0, 6B 100:100:100",
		"is_Attention_Model": true,
		"load_checkpoint":false,
		"run": true,
		"evaluate_dev": true,
		"max_out": false,
		"forget_bias":1.0,
		"n_hidden": 100,
		"input_keep_prob":0.9,
		"share_lstm_weights":true,
		"encoder_low_freq":1.0,
		"encoder_high_freq": 10000.0,
		"encoder_learn_freq": false,
                "encoder_step_skip_size": -75.0,
                "encoder_no_cross": true,
		"full_trainable_encoder": false,
		"multi_head_size": 4,
		"word_emb_size_after_scaling":100,
		"attention_emb_size": 100,
		"FeedForward_Hidden_Size": 200,
		"process_emb_size": 100,
                "time_encoding": true,
		"n_pre_layer": 3,
		"n_post_layer":0,
                "char_embedding":false,
		"pre_trained_char":false,
		"char_embedding_size":8,
		"char_convolution_size": 5,
		"char_convolution_padding":"NOT IMPLEMENTED",
		"char_out_size":100,
		"word2vec_scaling": true,
		"char&word2vec_scaling": false,
		"variance_char_init":1.0,
		"highway_type":"word",
		"highway_num_layers":2,
		"q_variables_reduction":0.25,
		"q_multi_head_size":1,
		"UNK=zero":false,
		"alternating_y1_y2":false,
		"encoder_initial_step":500,
		"encode_char_and_vec_separately":false,
                "encoder_scaling":false,
		"one_layer_reduction":false,
		"reduced_layer_dropout_amplification":1.0,
		"second_loss":false,
		"number_of_totens":0,
		"y1_sel":"all_layers",
        	"y2_sel":"linear"
	},
	"train":{
		"check_available_memory":  false,
		"train": true,
		"batch_size":75,
		"steps":600000,
		"steps_to_save": 3000,
		"steps_to_email":21000,
		"type": "Adam",
		"Adam":     {"learning_rate":1.0, "decay_rate":0.5,"beta1":0.9, "beta2":0.98, "epsilon":1e-8, "WarmupSteps":4000.0, "constant_LR":true},
		"Adadelta": {"learning_rate":1.0, "decay_steps": 1000, "decay_rate": 0.99, "rho":0.95},
		"Adagrad": {"learning_rate":0.05, "initial_accumulator_value":0.1},
		"RMS": {"learning_rate":0.05, "decay":0.9, "momentum":0.1},
		"dropout_encoder": 0.90,
		"dropout_attention": 0.9,
		"dropout_FF": 0.9,
		"dropout_Relu": 1.0,
		"dropout_concat": 1.0,
		"dropout_attention_pre_softmax":1.0,
		"dropout_attention_post_softmax":1.0,
		"dropout_selector":0.8,
		"dropout_char_pre_conv":0.75,
		"dropout_char_post_conv":1.0,
		"dropout_word_passage":1.0,
		"dropout_last_layer_passage":0.8,
		"label_smoothing": 0.90,
		"gaussian_smoothing":true,
		"moving_encoder_regularization":false,
		"xavier_initialization":true
	},
	"weights_init":{
		"W_Scaling_Variance": "NOT_IMPLEMENTED",
		"pre_trained_scaling_matrix": false
	},
	"model_options":{
		"norm_layer": true,
		"layer_type": "original",
        	"switching_model":false,
        	"word2vec_scaling": "matrix",
		"word2vec_orthonormal_scaling":false,
		"use_bias": true,
		"encoder_normalization": false
				}
}
