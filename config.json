{
	"glove":{
		"Comment_":"#Specifications of the glove model to use",
        	"dir":"./data/glove",
        	"corpus":"6B",
        	"vec_size":"300",
        	"db":"write-math"
    },
	"directories":{
		"Comment_":"#Directories info.",
		"source_dir":"./data/squad/",
		"target_dir":"./",
		"out_dir":"./"
	},
	"pre":{
		"Comments_":"Define preprocessing. Run: if the preprocess is run. Split: Split paragraph into sentences. word_count_th=number of times a word nees to appear to be counted as known",
		"run": false,
		"n_chunks": 30,
		"lower_word": true,
		"finetune": false,
		"data_filter": true,
		"word_count_th": 10,
		"char_count_th": 50,
		"max_question_size": 60,
		"max_paragraph_size": 400,
		"known_if_glove": true,
		"use_glove_for_unk": true
	},
	"model":{
		"Comment_":"All variables related to the model's architecture and training",
		"is_Attention_Model": true,
		"load_checkpoint":false,
		"run": true,		
		"evaluate_dev": true,
		"forget_bias":1.0,
		"n_hidden": 100,
		"char_vocabulary_size":30,
		"input_keep_prob":0.8,
		"share_lstm_weights":true,
		"encoder_base_freq": 10.0,
		"multi_head_size": 4,
		"attention_emb_size": 128,
		"FeedForward_Hidden_Size": 512
	},
	"train":{
		"train": true,
		"batch_size":14,
		"steps":216000,
		"steps_to_save": 2000,
		"type": "Adam",
		"Adam":     {"learning_rate":1.0, "decay_rate":0.5,"beta1":0.9, "beta2":0.98, "epsilon":1e-9, "WarmupSteps":4000.0},
		"AdaDelta": {"learning_rate":0.5, "decay_steps": 200, "decay_rate": 1.0},
		"dropout_att_encoder": 0.1,
                "dropout_att_sublayer": 0.1,
		"label_smoothing": 0.9
	},
	"weights_init":{
		"W_Scaling_Variance": 1e-3}
}
